{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "sHMIeeRPtpuJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TitanicDataset(Dataset):\n",
        "  def __init__(self, filepath):\n",
        "    data = TitanicDataset.clean_data(filepath)\n",
        "\n",
        "    x = data.drop(columns=['Survived'])\n",
        "    y = data['Survived']\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(x)\n",
        "\n",
        "    self.x = torch.tensor(X, dtype=torch.float32)\n",
        "    self.y = torch.tensor(y.values, dtype=torch.float32)\n",
        "\n",
        "    self.y = self.y.view(self.y.shape[0], 1)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.x[index], self.y[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.x.shape[0]\n",
        "\n",
        "  @staticmethod\n",
        "  def clean_data(filepath):\n",
        "    data = pd.read_csv(filepath)\n",
        "    data = data.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'])\n",
        "\n",
        "    data['Age'].fillna(data['Age'].mean(), inplace=True)\n",
        "    # data['Cabin'].fillna('Unknown', inplace=True)\n",
        "    data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "    label_columns = ['Embarked', 'Sex']\n",
        "\n",
        "    for col in label_columns:\n",
        "      le = LabelEncoder()\n",
        "      data[col] = le.fit_transform(data[col])\n",
        "\n",
        "    return data\n",
        "\n",
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self, n_input_features):\n",
        "    super(LogisticRegression, self).__init__()\n",
        "    self.linear = nn.Linear(in_features=n_input_features, out_features=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    y_predicted = torch.sigmoid(self.linear(x))\n",
        "    return y_predicted\n",
        ""
      ],
      "metadata": {
        "id": "m7c_-oyDxDK7"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_dataset = TitanicDataset('/content/data/train.csv')\n",
        "# # for i in range(len(train_dataset)):\n",
        "# #   print(train_dataset[i])\n",
        "# print(train_dataset[0][0].shape[0])\n",
        "# print(train_dataset[0][1].shape)\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FsG-CHP79Kd7"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Data\n",
        "train_dataset = TitanicDataset('/content/data/train.csv')\n",
        "dataloader = DataLoader(dataset=train_dataset, batch_size=25, shuffle=True)\n",
        "\n",
        "# Model\n",
        "model = LogisticRegression(train_dataset[0][0].shape[0])\n",
        "\n",
        "eta = 0.01\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(params=model.parameters(), lr=eta)\n",
        "\n",
        "n_epoch = 1000\n",
        "\n",
        "# Train\n",
        "for epoch in range(n_epoch):\n",
        "  for i, (input, label) in enumerate(dataloader):\n",
        "    y_hat = model(input)\n",
        "    loss = criterion(y_hat, label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "  if epoch % 100 == 0:\n",
        "    print(f'Epoch: {epoch+1}/{n_epoch}')\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "101P9ZHi9dg2",
        "outputId": "45eda611-f50d-44cb-d921-28047ea29a95"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/1000\n",
            "Epoch: 101/1000\n",
            "Epoch: 201/1000\n",
            "Epoch: 301/1000\n",
            "Epoch: 401/1000\n",
            "Epoch: 501/1000\n",
            "Epoch: 601/1000\n",
            "Epoch: 701/1000\n",
            "Epoch: 801/1000\n",
            "Epoch: 901/1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Data\n",
        "test_data = train_dataset.clean_data('/content/data/test.csv')\n",
        "\n",
        "scaler = StandardScaler()\n",
        "test_data = scaler.fit_transform(test_data)\n",
        "\n",
        "X_test = torch.tensor(test_data, dtype=torch.float32)\n",
        "pred = None\n",
        "with torch.no_grad():\n",
        "  y_prediction = model(X_test)\n",
        "  # print(y_prediction)\n",
        "  pred = y_prediction.round()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "idiYrp8hA762"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store as csv\n",
        "test = pd.read_csv('/content/data/test.csv')\n",
        "passenger_ids = test['PassengerId']\n",
        "\n",
        "passenger_ids_np = passenger_ids.values.astype(int).reshape(-1, 1)\n",
        "prediction_np = pred.numpy().astype(int).reshape(-1, 1)\n",
        "\n",
        "combined_data = np.concatenate((passenger_ids_np, prediction_np), axis=1)\n",
        "\n",
        "df = pd.DataFrame(combined_data, columns=['PassengerId', 'Survived'])\n",
        "pred_path = '/content/data/prediction.csv'\n",
        "\n",
        "df.to_csv(pred_path, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuUbKY75FdnL",
        "outputId": "4b7cb518-48cd-408f-f696-89c46927251e"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-74-c60dbbb7f407>:6: RuntimeWarning: invalid value encountered in cast\n",
            "  prediction_np = pred.numpy().astype(int).reshape(-1, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooh5n27XItrh",
        "outputId": "b7318127-a760-4d0d-8150-4892516b8c72"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([418, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8IktOwUAJm71"
      },
      "execution_count": 75,
      "outputs": []
    }
  ]
}